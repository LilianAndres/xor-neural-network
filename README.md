# XOR Neural Network with NumPy

A simple fully connected neural network implemented **from scratch** using NumPy to solve the XOR problem. Perfect for understanding the math behind neural networks! ğŸ§ âœ¨

## Features ğŸš€
- Fully connected feedforward neural network
- Implemented **without any deep learning frameworks**
- Includes forward pass, backward pass, and training loop
- Works on the classic XOR problem

## How it Works ğŸ§©
1. Input layer: 2 neurons (for XOR inputs)
2. Hidden layer: 2 neurons with ReLu activation
3. Output layer: 1 neuron with Sigmoid activation
4. Training: Gradient descent with mean squared error loss

This simple network demonstrates how even a small neural network can solve a non-linear problem like XOR.

## Contributing ğŸ¤
Feel free to fork this repo, improve the code, or experiment with other activation functions and learning rates!

## License ğŸ“„
This project is under MIT license.
